import cv2
import numpy
import math
from enum import Enum
from networktables import NetworkTables
import sys
import requests
from scipy.interpolate import interp1d
import math


class GripPipeline:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsv_threshold_hue = [33.99280575539568, 69.419795221843]
        self.__hsv_threshold_saturation = [194.91906474820144, 255.0]
        self.__hsv_threshold_value = [119.24460431654676, 255.0]

        self.hsv_threshold_output = None

        self.__find_contours_input = self.hsv_threshold_output
        self.__find_contours_external_only = False

        self.find_contours_output = None

        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area = 20.0
        self.__filter_contours_min_perimeter = 0
        self.__filter_contours_min_width = 0
        self.__filter_contours_max_width = 1000
        self.__filter_contours_min_height = 0
        self.__filter_contours_max_height = 1000
        self.__filter_contours_solidity = [0, 100]
        self.__filter_contours_max_vertices = 1000000
        self.__filter_contours_min_vertices = 0
        self.__filter_contours_min_ratio = 0
        self.__filter_contours_max_ratio = 1000

        self.filter_contours_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSV_Threshold0:
        self.__hsv_threshold_input = source0
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input, self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsv_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.find_contours_output
        (self.filter_contours_output) = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)


    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        im2, contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        return contours

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        output = []
        for contour in input_contours:
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            output.append(contour)
        return output

front_cam = None
back_cam = None


# camera.py

def camerainit(ip):
    global front_cam
    global back_cam
    # Front camera var
    front_cam = cv2.VideoCapture("http://" + ip + ":1182/stream.mjpg")


# Front camera functions
def cameragetFront():
    global front_cam
    ret_val, frame = front_cam.read()
    return ret_val, frame


# Back camera functions
def cameragetBack():
    global back_cam
    ret_val, frame = back_cam.read()
    return frame

robot_modes = Enum("Mode", "sandstorm teleop")

vision_table = None


def ntinit(ip):
	global vision_table
	NetworkTables.initialize(server='10.50.24.2')
	vision_table = NetworkTables.getTable("SmartDashboard/Vision")

def ntpublish(rotation, distance):
	global vision_table

	# Publish the data
	vision_table.putNumber("angle 1", rotation)
	vision_table.putNumber("angle 2", distance)

def ntgetMode():
	if bool(vision_table.getNumber("isTeleop", 1.0)):
		return robot_modes.teleop
	else:
		return robot_modes.sandstorm

# __main__.py

print("Starting DeepVision")
if len(sys.argv) == 2:
    roborio_address = sys.argv[1]
else:
    roborio_address = "10.50.24.2"
    # [ROBO_RIO ADDRESS HERE ^]

# Boring math ahead --> interpolate one dimension from sci-py

m1  = interp1d([300, 600], [0, 1])
m2 = interp1d([0, 299], [-1, 0])

# Find me that Robo-RIO!!

print("Checking for RoboRIO")

# Init Network Tables

ntinit(roborio_address)
camerainit(roborio_address)

# Initializing GRIP pipeline(boop, beep)

pipeline = grip.GripPipeline()

# Init vars for Calculations in while loop

cameraWidth = 160
fov         = 60
degPerPixel = cameraWidth / fov

while True:

    # Get frame from front camera

    isframe, front_frame = cameragetFront()
    if not isframe:
    	continue

    # Parse grip profile

    pipeline.process(front_frame)

    # C is for contours and contours are for me

    cookies = pipeline.filter_contours_output

    # Lambda functions, that select first and second elemets of a tuple        
    l1 = lambda x: x[0]
    l2 = lambda x: x[1]


    # Sorting the array of corners into the top-inside vertex.
    
    try:
        # Sort points of both boxes vertically
            
        bx1vert = sorted(cv2.boxPoints(cv2.minAreaRect(cookies[0])),key=l2)
        bx2vert = sorted(cv2.boxPoints(cv2.minAreaRect(cookies[1])),key=l2)

        # Choose both first and second elements of both

        x1t1, _ = bx1vert[0]
        x1t2, _ = bx1vert[1]

        x2t1, _ = bx2vert[0]
        x2t2, _ = bx2vert[1]

        # This essentially accounts for errors: from the highest two points, choose the one with
        # the bigger x value

        if(x1t1 > x1t2):
            x1 = x1t1
        else:
            x1 = x1t2
        if(x2t1 > x2t2):
            x2 = x2t1
        else:
            x2 = x2t2
       
        
    except:
        if len(cookies) == 1:
            bx1vert = sorted(cv2.boxPoints(cv2.minAreaRect(cookies[0])),key=l2)
            x1, _ = bx1vert[1]
            x2    = x1
        else:
            ntpublish(0.0, 0.0)
            continue

    # Math to find the center of 2 contours then use their center to calculate the center of those

    centre       = (x1 + x2) / 2
    displacement = (cameraWidth-1) / 2 - centre
    angle        = displacement / degPerPixel
    widthpx      = abs(int(x2 - x1))

    # Focal length = width(in px) * distance / width(inches)
    # distance() was measured manually

    # 8 is distance between 2 closest points, found in game manual

    # Calibration measurements (coding)

    measuredwidthpx = 43
    widthinch = 9
    measureddistance = 42
    flength = measuredwidthpx * measureddistance / widthinch

    # A new method to find angle

    angle2 = math.degrees(math.atan(displacement/ flength))



    # So that we don't divide by zero and kill the entire planet

    if (widthpx > 0):
        distance = (widthinch * flength / widthpx)

        # Measuring the z value

        zpx = centre
        pxtoinch = widthinch / widthpx
        zinch = zpx * pxtoinch
    else:
        distance = 0
        zinch = 0

    # Print to console {TESTING}

    print(f" {angle}  ")

    # Publish to networks tables.
    
    ntpublish(angle * -1, angle2 * -1)
